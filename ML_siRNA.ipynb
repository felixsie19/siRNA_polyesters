{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e9678e6-bef3-4ff4-b217-a18f21899529",
   "metadata": {},
   "source": [
    "# Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c7b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"combined_monomers_rdkit_new.xlsx\")\n",
    "df = df.dropna(subset=[\"Knockdown\", \"molecular_weight\"])\n",
    "df = df.dropna(axis=1)\n",
    "df = pd.get_dummies(df, columns=['cell type'])\n",
    "df.loc[df[\"Knockdown\"] == 1, \"Knockdown\"] = 0\n",
    "df.loc[df[\"Knockdown\"] == 3, \"Knockdown\"] = 2\n",
    "df.loc[df[\"Knockdown\"] == 2, \"Knockdown\"] = 1\n",
    "for col in df.columns:\n",
    "    if col.endswith('1'):\n",
    "        df[col] = df[col] * (1 - df[\"lipophil_w\"])\n",
    "    elif col.endswith('2'):\n",
    "        df[col] = df[col] * df[\"lipophil_w\"]\n",
    "X = df.drop([\"Polymer Name\", \"Knockdown\"], axis=1)\n",
    "y = df.Knockdown.astype(int)\n",
    "accuracies = None\n",
    "conf_matrices = None\n",
    "print(y.value_counts())\n",
    "\n",
    "models = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    ExtraTreesClassifier(),\n",
    "    SVC(),\n",
    "    MLPClassifier(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(),\n",
    "    XGBClassifier(),\n",
    "    LGBMClassifier(verbose=-1),\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    'Decision Tree',\n",
    "    'Random Forest',\n",
    "    'Extra Trees',\n",
    "    'SVC',\n",
    "    'MLP',\n",
    "    'Naive Bayes',\n",
    "    'KNN',\n",
    "    'XGBoost',\n",
    "    'LightGBM'\n",
    "]\n",
    "\n",
    "accuracies = {name: [] for name in model_names}\n",
    "conf_matrices = {name: [] for name in model_names}\n",
    "\n",
    "scaler = StandardScaler()\n",
    "unique_labels = np.unique(y)\n",
    "\n",
    "for split in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    #scaler can be switched on or off\n",
    "    #X_train = scaler.fit_transform(X_train)\n",
    "    #X_test = scaler.transform(X_test)\n",
    "\n",
    "    #resampling can be adjusted and switched on or off\n",
    "    #oversampler =RandomOverSampler(sampling_strategy={1: 500})\n",
    "    #undersampler = RandomUnderSampler()\n",
    "    #X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "    #X_train, y_train = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "        accuracies[name].append(accuracy)\n",
    "        \n",
    "        cm = np.zeros((len(unique_labels), len(unique_labels)), dtype=int)\n",
    "        \n",
    "        cm_temp = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
    "        \n",
    "        for i, label in enumerate(unique_labels):\n",
    "            for j, _ in enumerate(unique_labels):\n",
    "                cm[i, j] = cm_temp[i, j] if i < cm_temp.shape[0] and j < cm_temp.shape[1] else 0\n",
    "                \n",
    "        conf_matrices[name].append(cm)\n",
    "\n",
    "for name in model_names:\n",
    "    mean_accuracy = np.mean(accuracies[name])\n",
    "    std_dev_accuracy = np.std(accuracies[name])\n",
    "    print(\"{} BAc: {} SDA: {}\".format(name, mean_accuracy, std_dev_accuracy))\n",
    "\n",
    "\n",
    "    avg_cm = np.mean(conf_matrices[name], axis=0)\n",
    "    print(avg_cm)\n",
    "\n",
    "\n",
    "max_values = [max(values) for values in accuracies.values()]\n",
    "print(\"MAX_acc: \", max_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bf663",
   "metadata": {},
   "source": [
    "# Hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "df = pd.read_excel(\"combined_monomers_rdkit_new.xlsx\")\n",
    "df = df.dropna(subset=[\"Knockdown\", \"molecular_weight\"])\n",
    "df = df.dropna(axis=1)\n",
    "df = pd.get_dummies(df, columns=['cell type'])\n",
    "df.loc[df[\"Knockdown\"] == 1, \"Knockdown\"] = 0\n",
    "df.loc[df[\"Knockdown\"] == 3, \"Knockdown\"] = 2\n",
    "df.loc[df[\"Knockdown\"] == 2, \"Knockdown\"] = 1\n",
    "for col in df.columns:\n",
    "    if col.endswith('1'):\n",
    "        df[col] = df[col] * (1 - df[\"lipophil_w\"])\n",
    "    elif col.endswith('2'):\n",
    "        df[col] = df[col] * df[\"lipophil_w\"]\n",
    "df = df.drop(df.columns[-1], axis=1)\n",
    "X = df.drop([\"Polymer Name\", \"Knockdown\"], axis=1)\n",
    "y = df.Knockdown.astype(int)\n",
    "\n",
    "oversampler = SMOTEENN()\n",
    "\n",
    "space = {\n",
    "    'num_leaves': hp.choice('num_leaves', range(20, 150)), \n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),  \n",
    "    'n_estimators': hp.choice('n_estimators', range(100, 1000)),  \n",
    "    'max_depth': hp.choice('max_depth', range(5, 20)), \n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),  \n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),  \n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0)  \n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    model = LGBMClassifier(\n",
    "        verbose = -1,\n",
    "        num_leaves=int(params['num_leaves']),\n",
    "        learning_rate=params['learning_rate'],\n",
    "        n_estimators=int(params['n_estimators']),\n",
    "        max_depth=int(params['max_depth']),\n",
    "        reg_lambda=params['reg_lambda'],\n",
    "        subsample=params['subsample'],\n",
    "        colsample_bytree=params['colsample_bytree']\n",
    "    )\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    for i in range (10):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "        X_train,y_train = oversampler.fit_resample(X_train,y_train)\n",
    "        X_train,y_train = undersampler.fit_resample(X_train,y_train)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        model = model.fit(X_train, y_train)  \n",
    "\n",
    "        preds = model.predict(X_test)\n",
    "        score = balanced_accuracy_score(y_test, preds)\n",
    "        scores.append(score)\n",
    "\n",
    "    average_score = np.mean(scores)\n",
    "    \n",
    "    return -average_score \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_hyperparams = fmin(fn=objective,\n",
    "                        space=space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=100,\n",
    "                        trials=trials)\n",
    "\n",
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d6bc76-2dfa-49d1-905d-c0cdc1bb0d0c",
   "metadata": {},
   "source": [
    "# Model stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478eebab-e736-49d8-902d-5c87609ac70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "features_to_keep=[\"BalabanJ1\",\"fr_piperdine1\",\"MaxAbsEStateIndex1\",\"BCUT2D_MRLOW3\",\"BCUT2D_MRLOW1\",\"EState_VSA32\",\"Ipc2\",\"fr_NH01\",\"FpDensityMorgan21\",\"PBF1\",\"VSA_EState91\"]    \n",
    "# Parameters\n",
    "params = {\n",
    "    'colsample_bytree': 0.5280489323078961, 'learning_rate': 0.023499558736047456, \n",
    "    'max_depth': 8, 'n_estimators': 10, 'num_leaves': 110, 'reg_lambda': 0.8070820186132228, \n",
    "    'subsample': 0.8610806429810899\n",
    "}\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_excel(\"combined_monomers_rdkit_new.xlsx\")\n",
    "df = df.dropna(subset=[\"Knockdown\", \"molecular_weight\"])\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "#df = pd.get_dummies(df, columns=['cell type'])\n",
    "df.loc[df[\"Knockdown\"] == 1, \"Knockdown\"] = 0\n",
    "df.loc[df[\"Knockdown\"] == 3, \"Knockdown\"] = 2\n",
    "df.loc[df[\"Knockdown\"] == 2, \"Knockdown\"] = 1\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.endswith('1'):\n",
    "        df[col] = df[col] * (1 - df[\"lipophil_w\"])\n",
    "    elif col.endswith('2'):\n",
    "        df[col] = df[col] * df[\"lipophil_w\"]\n",
    "\n",
    "\n",
    "X = X[features_to_keep]\n",
    "feature_names = X.columns\n",
    "y = df.Knockdown.astype(int)\n",
    "# Models to evaluate\n",
    "#Possible to integrate other basic models as well\n",
    "models = [\n",
    "    LGBMClassifier(verbose=-1,**params)\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    'LightGBM (optimized)'\n",
    "]\n",
    "\n",
    "balanced_accuracies = {name: [] for name in model_names}\n",
    "conf_matrices = {name: [] for name in model_names} \n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "for split in range(100):\n",
    "    X_train_o, X_test, y_train_o, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    X_train_o = scaler.fit_transform(X_train_o)\n",
    "    X_test=scaler.transform(X_test)\n",
    "\n",
    "    \n",
    "\n",
    "    for model, name in zip(models, model_names):\n",
    "        X_train = X_train_o.copy()\n",
    "        y_train = y_train_o.copy()\n",
    "        if name=='LightGBM (optimized)':\n",
    "\n",
    "            oversampler = SMOTEENN(random_state=1)\n",
    "            X_train, y_train = oversampler.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_accuracies[name].append(balanced_acc)\n",
    "\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        conf_matrices[name].append(cm)\n",
    "\n",
    "for name in model_names:\n",
    "    mean_balanced_acc = np.mean(balanced_accuracies[name])\n",
    "    std_dev_balanced_acc = np.std(balanced_accuracies[name])\n",
    "    print(f\"{name} Balanced Accuracy: {mean_balanced_acc:.4f} (± {std_dev_balanced_acc:.4f})\")\n",
    "\n",
    "    avg_cm = np.mean(conf_matrices[name], axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(avg_cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Averaged Confusion Matrix for {name}')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()\n",
    "\n",
    "mean_balanced_accs = [np.mean(balanced_accuracies[name]) for name in model_names]\n",
    "std_dev_balanced_accs = [np.std(balanced_accuracies[name]) for name in model_names]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "print(balanced_accuracies['LightGBM (optimized)'])\n",
    "plt.plot(balanced_accuracies['LightGBM (optimized)'],marker='o', color='orange')\n",
    "\n",
    "plt.title('Model Stability')\n",
    "plt.xlabel('Iteration Number')\n",
    "plt.ylabel('Balanced Accuracy Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0711ba-bfe7-445a-b2f9-937e66a15779",
   "metadata": {},
   "source": [
    "# Compare resampling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbb78bc-50d8-44b0-aae8-7f3849feb7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score\n",
    "from lightgbm import LGBMClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import EditedNearestNeighbours as ENN\n",
    "\n",
    "\n",
    "params={'colsample_bytree': 0.9755088786798269, 'learning_rate': 0.1827587842746705, 'max_depth': 8, 'n_estimators': 465, 'num_leaves': 85, 'reg_lambda': 0.8324249896997891, 'subsample': 0.9331718683905172}\n",
    "# Load and prepare data\n",
    "df = pd.read_excel(\"combined_monomers_rdkit_new.xlsx\")\n",
    "df = df.dropna(subset=[\"Knockdown\", \"molecular_weight\"])\n",
    "df = df.dropna(axis=1)\n",
    "df = pd.get_dummies(df, columns=['cell type'])\n",
    "df.loc[df[\"Knockdown\"] == 1, \"Knockdown\"] = 0\n",
    "df.loc[df[\"Knockdown\"] == 3, \"Knockdown\"] = 2\n",
    "df.loc[df[\"Knockdown\"] == 2, \"Knockdown\"] = 1\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.endswith('1'):\n",
    "        df[col] = df[col] * (1 - df[\"lipophil_w\"])\n",
    "    elif col.endswith('2'):\n",
    "        df[col] = df[col] * df[\"lipophil_w\"]\n",
    "\n",
    "\n",
    "# Define resampling strategies\n",
    "resampling_strategies = {\n",
    "    'without resampling': None,\n",
    "    'Oversampling': RandomOverSampler(sampling_strategy=\"auto\"),\n",
    "    'Undersampling': RandomUnderSampler(),\n",
    "    'SMOTE': SMOTE(sampling_strategy=\"auto\"),\n",
    "    'SMOTEENN (default)': SMOTEENN(random_state=1),\n",
    "    'SMOTEENN (auto)': SMOTEENN(smote=SMOTE(sampling_strategy=\"auto\"), enn=ENN(sampling_strategy='auto')),\n",
    "    'SMOTE + Undersampling (80%)': (SMOTE(sampling_strategy={1: 500}), RandomUnderSampler()),\n",
    "}\n",
    "\n",
    "# Initialize variables to store results\n",
    "balanced_accuracies = {name: [] for name in resampling_strategies}\n",
    "conf_matrices = {name: [] for name in resampling_strategies}\n",
    "test_point_results = {name: [] for name in resampling_strategies}\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Model to evaluate\n",
    "model = LGBMClassifier(verbose=-1, **params)\n",
    "\n",
    "# Evaluate each resampling strategy\n",
    "for strategy_name, strategy in resampling_strategies.items():\n",
    "    for split in range(100):\n",
    "        X = df.drop([\"Polymer Name\", \"Knockdown\",\"molecular_weight\"], axis=1)\n",
    "        test_point = X.iloc[-1]\n",
    "        X = X.iloc[:-1] \n",
    "        feature_names = X.columns\n",
    "        y = df.Knockdown.astype(int).iloc[:-1]\n",
    "        print(f\"Starting split number {split+1}/100 for {strategy_name}: \")\n",
    "      \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        test_point = scaler.transform([test_point])\n",
    "        \n",
    "        if isinstance(strategy, tuple):\n",
    "            smote, undersample = strategy\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "            X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "        elif strategy is None:\n",
    "            pass\n",
    "        else:\n",
    "            X_train, y_train = strategy.fit_resample(X_train, y_train)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate balanced accuracy\n",
    "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        balanced_accuracies[strategy_name].append(balanced_acc)\n",
    "        \n",
    "        test_predict = model.predict_proba(test_point)[:, 1]\n",
    "        test_point_results[strategy_name].append(test_predict)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        conf_matrices[strategy_name].append(cm)\n",
    "\n",
    "for strategy_name in resampling_strategies:\n",
    "    mean_balanced_acc = np.mean(balanced_accuracies[strategy_name])\n",
    "    std_dev_balanced_acc = np.std(balanced_accuracies[strategy_name])\n",
    "    print(f\"{strategy_name} Balanced Accuracy: {mean_balanced_acc:.4f} (± {std_dev_balanced_acc:.4f})\")\n",
    "    \n",
    "    mean_test_point = np.mean(test_point_results[strategy_name])\n",
    "    print(f\"Avg Test Point Proba: {mean_test_point}\")\n",
    "    \n",
    "    avg_cm = np.mean(conf_matrices[strategy_name], axis=0)\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(avg_cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "    plt.title(f'Averaged Confusion Matrix for {strategy_name}')\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()\n",
    "\n",
    "mean_balanced_accs = [np.mean(balanced_accuracies[name]) for name in resampling_strategies]\n",
    "std_dev_balanced_accs = [np.std(balanced_accuracies[name]) for name in resampling_strategies]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(resampling_strategies.keys(), mean_balanced_accs, yerr=std_dev_balanced_accs, capsize=5, color='skyblue')\n",
    "plt.title('Resampling Strategy Comparison Based on Balanced Accuracy')\n",
    "plt.xlabel('Resampling Strategy')\n",
    "plt.ylabel('Balanced Accuracy Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.savefig('Resampling_Strategy_Comparison_Balanced_Accuracy.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958c2598-1957-49b4-8ebc-a50d8fd590ea",
   "metadata": {},
   "source": [
    "# Feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8e06b-5cde-4b09-b78e-9999fec9b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "import umap.umap_ as umap\n",
    "\n",
    "\n",
    "params={'colsample_bytree': 0.9755088786798269, 'learning_rate': 0.1827587842746705, 'max_depth': 8, 'n_estimators': 465, 'num_leaves': 85, 'reg_lambda': 0.8324249896997891, 'subsample': 0.9331718683905172}\n",
    "\n",
    "df = pd.read_excel(\"combined_monomers_rdkit_new.xlsx\")\n",
    "df = df.dropna(subset=[\"Knockdown\", \"molecular_weight\"])\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "df.loc[df[\"Knockdown\"] == 1, \"Knockdown\"] = 0\n",
    "df.loc[df[\"Knockdown\"] == 3, \"Knockdown\"] = 2\n",
    "df.loc[df[\"Knockdown\"] == 2, \"Knockdown\"] = 1\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.endswith('1'):\n",
    "        df[col] = df[col] * (1 - df[\"lipophil_w\"])\n",
    "    elif col.endswith('2'):\n",
    "        df[col] = df[col] * df[\"lipophil_w\"]\n",
    "scaler = StandardScaler()\n",
    "unique_labels = np.unique(y)\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "model = LGBMClassifier(verbose=-1, **params)\n",
    "df[\"paper\"]=df[\"Polymer Name\"].str.split(\"_\",expand=True)[0]\n",
    "paper=df[\"paper\"].iloc[:-1]\n",
    "features_to_drop=[\"paper\",\"Polymer Name\", \"Knockdown\"]\n",
    "X = df.drop(features_to_drop, axis=1)\n",
    "X=pd.get_dummies(X,drop_first=False)\n",
    "print(X.columns)\n",
    "feature_names=X.columns\n",
    "y = df.Knockdown.astype(int)\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "Xresampled, yresampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "model.fit(Xresampled, yresampled)\n",
    "\n",
    "feature_importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "top_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(11)\n",
    "print(\"Top 11 Most Important Features:\")\n",
    "print(top_features)\n",
    "\n",
    "top_11_features = top_features['Feature'].values  \n",
    "X_top11 = df[top_11_features] \n",
    "y = df.Knockdown.astype(int)\n",
    "\n",
    "X_top11 = scaler.fit_transform(X_top11)\n",
    "X_top11 = pd.DataFrame(X_top11, columns=top_11_features)  \n",
    "\n",
    "with open(\"combined_monomers_fingerprints_2024-12-30_11-44-29.pkl\",\"rb\") as f:\n",
    "    combined_df=pickle.load(f)\n",
    "\n",
    "publication=combined_df['Paper Name']\n",
    "X_fp = combined_df.drop(['Paper Name'],axis=1)\n",
    "X_fp = X_fp.dropna(axis=1)\n",
    "umap_params = {\n",
    "  'n_neighbors': len(df), \n",
    "  'min_dist': 1, \n",
    "  'spread': 1, \n",
    "  'metric': 'euclidean', \n",
    "  'random_state': 1\n",
    "}\n",
    "\n",
    "umap_fp=umap.UMAP(n_components=2, **umap_params)\n",
    "umap_full = umap.UMAP(n_components=2, **umap_params)\n",
    "umap_reduced = umap.UMAP(n_components=2, **umap_params)\n",
    "\n",
    "embedding_fp=umap_fp.fit_transform(X_fp)\n",
    "embedding_full = umap_full.fit_transform(X)\n",
    "embedding_reduced = umap_reduced.fit_transform(X_top11)\n",
    "\n",
    "binary_colors = ['red', 'green',\"blue\"]  \n",
    "\n",
    "unique_labels = np.unique(paper)\n",
    "color_map = {label: binary_colors[i % len(binary_colors)] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "y_color_fp = [color_map[label] for label in publication]\n",
    "y_colors = [color_map[label] for label in paper]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 8))\n",
    "\n",
    "axes[0].scatter(\n",
    "    embedding_fp[:, 0], \n",
    "    embedding_fp[:, 1], \n",
    "    c=y_color_fp, \n",
    "    edgecolor='k', \n",
    "    alpha=0.7\n",
    ")\n",
    "axes[0].set_title(\"UMAP Projection: Morgan Fingerprints\")\n",
    "axes[0].set_xlabel(\"UMAP 1\")\n",
    "axes[0].set_ylabel(\"UMAP 2\")\n",
    "\n",
    "\n",
    "axes[1].scatter(\n",
    "    embedding_full[:, 0], \n",
    "    embedding_full[:, 1], \n",
    "    c=y_colors,  \n",
    "    edgecolor='k', \n",
    "    alpha=0.7\n",
    ")\n",
    "axes[1].set_title(\"UMAP Projection: Full Features\")\n",
    "axes[1].set_xlabel(\"UMAP 1\")\n",
    "axes[1].set_ylabel(\"UMAP 2\")\n",
    "\n",
    "axes[2].scatter(\n",
    "    embedding_reduced[:, 0], \n",
    "    embedding_reduced[:, 1], \n",
    "    c=y_colors,  \n",
    "    edgecolor='k', \n",
    "    alpha=0.7\n",
    ")\n",
    "axes[2].set_title(\"UMAP Projection: Reduced Features\")\n",
    "axes[2].set_xlabel(\"UMAP 1\")\n",
    "axes[2].set_ylabel(\"UMAP 2\")\n",
    "\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10, label=f\"Dataset {label}\")\n",
    "           for label, color in color_map.items()]\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4669e7-d834-48a6-b688-53fcd4174dbe",
   "metadata": {},
   "source": [
    "# Predictions and SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce5b9b4-8e9f-4527-a083-dc2efbdf0ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.combine import SMOTEENN\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "params={'colsample_bytree': 0.9755088786798269, 'learning_rate': 0.1827587842746705, 'max_depth': 8, 'n_estimators': 465, 'num_leaves': 85, 'reg_lambda': 0.8324249896997891, 'subsample': 0.9331718683905172}\n",
    "\n",
    "df = pd.read_excel(\"combined_monomers_rdkit_new.xlsx\")\n",
    "df = df.dropna(subset=[\"Knockdown\", \"molecular_weight\"])\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "df.loc[df[\"Knockdown\"] == 1, \"Knockdown\"] = 0\n",
    "df.loc[df[\"Knockdown\"] == 3, \"Knockdown\"] = 2\n",
    "df.loc[df[\"Knockdown\"] == 2, \"Knockdown\"] = 1\n",
    "\n",
    "for col in df.columns:\n",
    "    if col.endswith('1'):\n",
    "        df[col] = df[col] * (1 - df[\"lipophil_w\"])\n",
    "    elif col.endswith('2'):\n",
    "        df[col] = df[col] * df[\"lipophil_w\"]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "df_test=  pd.read_excel(\"/home/akm/Felix_ML/Moldescr_poly/siRNA_ML/New_revision_polymers/cleaned/test_polymers_new.xlsx\")\n",
    "\n",
    "df_test = df_test.dropna(axis=1)\n",
    "\n",
    "for col in df_test.columns:\n",
    "    if col.endswith('1'):\n",
    "        df_test[col] = df_test[col] * (1 - df_test[\"lipophil_w\"])\n",
    "    elif col.endswith('2'):\n",
    "        df_test[col] = df_test[col] * df_test[\"lipophil_w\"]\n",
    "\n",
    "# Resampling strategy\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "model = LGBMClassifier(verbose=-1,**params)\n",
    "\n",
    "features_to_keep=[\"BalabanJ1\",\"fr_piperdine1\",\"MaxAbsEStateIndex1\",\"BCUT2D_MRLOW3\",\"BCUT2D_MRLOW1\",\"EState_VSA32\",\"Ipc2\",\"fr_NH01\",\"FpDensityMorgan21\",\"PBF1\",\"VSA_EState91\"]    \n",
    "y=df.Knockdown\n",
    "df_new=df[features_to_keep]\n",
    "trainset=df_new\n",
    "valset=df_test[features_to_keep]\n",
    "\n",
    "\n",
    "X = scaler.fit_transform(trainset)\n",
    "Xresampled, yresampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "model.fit(Xresampled, yresampled)                     \n",
    "\n",
    "X_test=scaler.transform(valset)\n",
    "\n",
    "print(model.predict(X_test))\n",
    "\n",
    "shap_values = shap.TreeExplainer(model).shap_values(Xresampled)\n",
    "\n",
    "shap.summary_plot(shap_values, Xresampled ,feature_names=features_to_keep)\n",
    "\n",
    "explainer=shap.TreeExplainer(model,X,feature_names=features_to_keep)\n",
    "\n",
    "explanation=explainer(X_test)\n",
    "shap.plots.waterfall(explanation[0])\n",
    "              "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
